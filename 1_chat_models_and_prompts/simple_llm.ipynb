{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple LLM application with chat models and prompt templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain has implementations for older language models that take a string as input and return a string as output. These models are typically named without the \"Chat\" prefix (e.g., Ollama, Anthropic, OpenAI, etc.), and may include the \"LLM\" suffix (e.g., OllamaLLM, AnthropicLLM, OpenAILLM, etc.). These models implement the BaseLLM interface.\n",
    "\n",
    "Users should be using almost exclusively the newer Chat Models as most model providers have adopted a chat like interface for interacting with language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao! Come posso aiutarti oggi?', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-04-04T06:10:32.7218029Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2862656900, 'load_duration': 33160300, 'prompt_eval_count': 24, 'prompt_eval_duration': 239000000, 'eval_count': 12, 'eval_duration': 2589000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-4965e76f-5f1d-442a-8743-af167ef5b6cf-0', usage_metadata={'input_tokens': 24, 'output_tokens': 12, 'total_tokens': 36})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of \"I love programming\" in French is:\n",
      "\n",
      "\"J'adore le programmation.\"\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao! Come posso aiutarti oggi?"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(messages):\n",
    "    print(chunk.text(), end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following are equivalent\n",
    "model.invoke(\"Hello\")\n",
    "\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "\n",
    "model.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}. Translate the given sentence.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: You are a helpful assistant that translates English to Hindi. Translate the given sentence.\\nHuman: What are you doing'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = prompt.invoke({\n",
    "    'input_language': \"English\",\n",
    "    'output_language': \"Hindi\",\n",
    "    'input': 'What are you doing'\n",
    "})\n",
    "op.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that translates English to Hindi. Translate the given sentence.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What are you doing', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = {\n",
    "    'input_language': \"English\",\n",
    "    'output_language': \"Hindi\",\n",
    "    'input': 'I love programming'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of \"I love programming\" in Hindi is:\n",
      "\n",
      "मैं प्रोग्रामिंग को पसंद करता हूँ।"
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream(ip):\n",
    "    print(chunk.text(), end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Hindi', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Hindi\", \"text\": \"I love programming\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Hindi', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I love programming', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मैं प्रोग्रामिंग को पसंद करता हूँ।\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9 ('langchain_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09a05abf15e19daf5b197e2aa63fe74df0715c2b0bf14a3e46cbfc8a9b98bbac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
